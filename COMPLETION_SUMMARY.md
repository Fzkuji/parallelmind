# HuggingFace + LoRA + 2D RoPE åŠŸèƒ½å®Œæˆæ€»ç»“

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œä¸º ParallelMind é¡¹ç›®æ·»åŠ äº†å®Œæ•´çš„ HuggingFace æ¨¡å‹ + LoRA + 2D RoPE è®­ç»ƒå’Œæ¨ç†åŠŸèƒ½ã€‚

## âœ… å·²å®Œæˆå·¥ä½œ

### 1. æ ¸å¿ƒåŠŸèƒ½å®ç°

#### è®­ç»ƒè„šæœ¬ (`trainer/train_hf_lora.py`)
- âœ… åŠ è½½ä»»æ„ HuggingFace CausalLM æ¨¡å‹
- âœ… è‡ªåŠ¨åº”ç”¨ 2D RoPEï¼ˆæ”¯æŒ branch + time äºŒç»´ä½ç½®ç¼–ç ï¼‰
- âœ… æ·»åŠ  LoRA å±‚è¿›è¡Œé«˜æ•ˆå¾®è°ƒ
- âœ… ä½¿ç”¨ Parallel æ•°æ®æ ¼å¼ï¼ˆ`ParallelPretrainDataset` + `ParallelPretrainCollator`ï¼‰
- âœ… æ”¯æŒå›ºå®šå’ŒåŠ¨æ€ branch æ¨¡å¼
- âœ… åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒï¼ˆDDPï¼‰
- âœ… æ··åˆç²¾åº¦è®­ç»ƒ
- âœ… æ¢¯åº¦ç´¯ç§¯
- âœ… W&B æ—¥å¿—è®°å½•

**å…³é”®å‚æ•°ï¼š**
```bash
--base_model              # HuggingFace æ¨¡å‹è·¯å¾„
--lora_rank               # LoRA ç§©
--rope_2d_ratio           # 2D RoPE é¢‘ç‡æ¯”ä¾‹
--batch_by_samples        # æŒ‰æ ·æœ¬æ•°æ‰¹æ¬¡
--max_branches_per_sample # åŠ¨æ€ branch æœ€å¤§å€¼
--min_branches_per_sample # åŠ¨æ€ branch æœ€å°å€¼
```

#### æ¨ç†è„šæœ¬ (`scripts/inference_hf_lora.py`)
- âœ… åŠ è½½åŸºç¡€æ¨¡å‹å’Œ LoRA æƒé‡
- âœ… **è‡ªåŠ¨å¤„ç† pos2d**ï¼ˆè§£å†³ GPT-5 å‘ç°çš„å…³é”®é—®é¢˜ï¼‰
- âœ… é‡å†™ `prepare_inputs_for_generation` å®ç°è‡ªåŠ¨ pos2d æ³¨å…¥
- âœ… æ”¯æŒäº¤äº’å¼å¯¹è¯æ¨¡å¼
- âœ… æ”¯æŒå•æ¬¡ç”Ÿæˆæ¨¡å¼
- âœ… æä¾› Python API è°ƒç”¨æ¥å£

**å…³é”®åˆ›æ–°ï¼špos2d è‡ªåŠ¨æ³¨å…¥æœºåˆ¶**
```python
def _inject_pos2d_hook(model):
    """é‡å†™ prepare_inputs_for_generationï¼Œä¿è¯å¢é‡ç”Ÿæˆä¹Ÿä¼šæºå¸¦ pos2d"""
    # ä¿å­˜åŸå§‹æ–¹æ³•
    model._orig_prepare_inputs_for_generation = model.prepare_inputs_for_generation

    def _prepare_inputs_for_generation(self, input_ids, **kwargs):
        inputs = self._orig_prepare_inputs_for_generation(input_ids, **kwargs)
        # è‡ªåŠ¨æ„é€  pos2d
        position_ids = inputs.get("position_ids")
        if position_ids is None:
            seq_len = inputs["input_ids"].size(-1)
            position_ids = torch.arange(seq_len, device=inputs["input_ids"].device).unsqueeze(0)
        branch_ids = torch.zeros_like(position_ids)
        pos2d = torch.stack([branch_ids, position_ids], dim=-1)
        # âš ï¸ å…³é”®ï¼šæ¯æ¬¡ç”Ÿæˆå‰è°ƒç”¨ set_rope_pos2d
        set_rope_pos2d(self, pos2d)
        return inputs

    # é‡å†™æ–¹æ³•
    model.prepare_inputs_for_generation = types.MethodType(_prepare_inputs_for_generation, model)
```

### 2. æ–‡æ¡£å®Œå–„

#### æ–°å»ºæ–‡æ¡£
1. **[docs/INFERENCE_GUIDE.md](docs/INFERENCE_GUIDE.md)** - è¯¦ç»†æ¨ç†æŒ‡å—
   - âš ï¸ é‡è¦æç¤ºï¼špos2d è‡ªåŠ¨å¤„ç†è¯´æ˜
   - ä¸‰ç§æ¨ç†æ–¹æ³•ï¼ˆäº¤äº’å¼ã€å•æ¬¡ã€Python APIï¼‰
   - å®Œæ•´å‚æ•°è¯´æ˜
   - å¸¸è§é—®é¢˜è§£ç­”
   - æ€§èƒ½ä¼˜åŒ–å»ºè®®

2. **[docs/TRAIN_HF_LORA_USAGE.md](docs/TRAIN_HF_LORA_USAGE.md)** - è®­ç»ƒä½¿ç”¨æ–‡æ¡£
   - å®Œæ•´å‚æ•°è¯´æ˜
   - ä¸åŒæ¨¡å‹é…ç½®ç¤ºä¾‹
   - æ€§èƒ½ä¼˜åŒ–å»ºè®®
   - æ•…éšœæ’æŸ¥

3. **[docs/POS2D_IMPLEMENTATION_SUMMARY.md](docs/POS2D_IMPLEMENTATION_SUMMARY.md)** - pos2d å®ç°æ€»ç»“
   - GPT-5 å‘ç°çš„é—®é¢˜è¯¦ç»†è¯´æ˜
   - è§£å†³æ–¹æ¡ˆæŠ€æœ¯ç»†èŠ‚
   - å·¥ä½œæµç¨‹å›¾
   - éªŒè¯ç»“æœ

4. **[docs/QUICK_START_LORA.md](docs/QUICK_START_LORA.md)** - å¿«é€Ÿå¼€å§‹æŒ‡å—
   - ä¸€åˆ†é’Ÿä¸Šæ‰‹ç¤ºä¾‹
   - æ ¸å¿ƒå‚æ•°é€ŸæŸ¥è¡¨
   - ä¸åŒæ¨¡å‹é…ç½®
   - å¸¸è§é—®é¢˜å¿«é€Ÿä¿®å¤
   - æœ€ä½³å®è·µ

#### æ›´æ–°æ–‡æ¡£
- **[README.md](README.md)** - ä¸»æ–‡æ¡£
  - ä¿®æ­£å‚æ•°å†²çªï¼ˆ`--branches_per_sample` vs `--max_branches_per_sample`ï¼‰
  - æ·»åŠ æ¨ç†è¯´æ˜
  - æ·»åŠ  pos2d è‡ªåŠ¨å¤„ç†è­¦å‘Š
  - æ·»åŠ å¿«é€Ÿå¼€å§‹æŒ‡å—é“¾æ¥

### 3. æµ‹è¯•å’ŒéªŒè¯

#### æµ‹è¯•è„šæœ¬
1. **[scripts/test_pos2d_handling.py](scripts/test_pos2d_handling.py)** - pos2d å•å…ƒæµ‹è¯•
   - æµ‹è¯• `_prepare_pos2d()` å‡½æ•°
   - æµ‹è¯• hook æ³¨å…¥æœºåˆ¶
   - æµ‹è¯•ä¸åŒåºåˆ—é•¿åº¦çš„ä¸€è‡´æ€§

2. **[scripts/validate_inference_setup.py](scripts/validate_inference_setup.py)** - å®Œæ•´éªŒè¯
   - æ¨¡å—å¯¼å…¥æ£€æŸ¥
   - è®­ç»ƒè„šæœ¬éªŒè¯
   - æ¨ç†è„šæœ¬éªŒè¯
   - æ–‡æ¡£å®Œæ•´æ€§æ£€æŸ¥
   - pos2d å·¥ä½œæµç¨‹éªŒè¯
   - æ–‡ä»¶ç»“æ„æ£€æŸ¥

3. **[scripts/test_inference.sh](scripts/test_inference.sh)** - å¿«é€Ÿæ¨ç†æµ‹è¯•
   - Bash è„šæœ¬å¿«é€Ÿæµ‹è¯•æ¨ç†æµç¨‹

#### éªŒè¯ç»“æœ
```
================================================================================
éªŒè¯ç»“æœæ±‡æ€»
================================================================================
æ¨¡å—å¯¼å…¥                 âœ… é€šè¿‡
è®­ç»ƒè„šæœ¬                 âœ… é€šè¿‡
æ¨ç†è„šæœ¬                 âœ… é€šè¿‡
æ–‡æ¡£å®Œæ•´æ€§                âœ… é€šè¿‡
pos2d å·¥ä½œæµç¨‹           âœ… é€šè¿‡
æ–‡ä»¶ç»“æ„                 âœ… é€šè¿‡
================================================================================
âœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼ç³»ç»Ÿå·²æ­£ç¡®é…ç½®
```

## ğŸ”§ å…³é”®é—®é¢˜è§£å†³ï¼šGPT-5 å‘ç°çš„ pos2d ç¼ºå¤±é—®é¢˜

### é—®é¢˜æè¿°
GPT-5 æŒ‡å‡ºï¼š
> **å¿…é¡»ç»™ 2D RoPE æ³¨å…¥ pos2d**
>
> `trainer/train_hf_lora.py`ã€`parallel_generate.py` åœ¨å‰å‘å‰éƒ½ä¼šè°ƒç”¨ `set_rope_pos2d`ï¼Œè€Œ Claude å†™çš„ `scripts/inference_hf_lora.py` åªæ˜¯ `patch_model_with_interleaved_2d_rope`ï¼Œå´æ²¡æœ‰åœ¨ forward/generate ä¹‹å‰è®¾ç½® pos2dã€‚
>
> å¦‚æœä½ å¼€å¯äº† `--patch_rope`ï¼Œé¦–æ¬¡æ¨ç†å°±ä¼šæŠ¥é”™ï¼š
> ```
> RuntimeError: extra_pos2d is not set. Call set_rope_pos2d first.
> ```

### è§£å†³æ–¹æ¡ˆ
å®ç°äº†ä¸‰å±‚ pos2d å¤„ç†æœºåˆ¶ï¼š

1. **`_prepare_pos2d()`** - ç”Ÿæˆ pos2d å¼ é‡
   - ä¸ºå•åˆ†æ”¯æ¨ç†ç”Ÿæˆæ­£ç¡®çš„ pos2d
   - `branch_ids` å…¨ä¸º 0ï¼ˆå•åˆ†æ”¯ï¼‰
   - `time_ids` çº¿æ€§é€’å¢ï¼ˆ0, 1, 2, ...ï¼‰

2. **`_inject_pos2d_hook()`** - é’©å­æ³¨å…¥
   - é‡å†™ `prepare_inputs_for_generation` æ–¹æ³•
   - æ¯æ¬¡å¢é‡ç”Ÿæˆå‰è‡ªåŠ¨è°ƒç”¨ `set_rope_pos2d()`

3. **`_set_prompt_pos2d()`** - é¦–æ¬¡å‰å‘ä¼ æ’­
   - åœ¨é¦–æ¬¡ç”Ÿæˆå‰æ˜¾å¼è®¾ç½® pos2d
   - å¤„ç†å®Œæ•´ prompt çš„ä½ç½®ç¼–ç 

### æ•ˆæœ
- âœ… ç”¨æˆ·ä½¿ç”¨ `scripts/inference_hf_lora.py` æ— éœ€å…³å¿ƒ pos2d
- âœ… è‡ªåŠ¨å¤„ç†é¦–æ¬¡å‰å‘å’Œå¢é‡ç”Ÿæˆ
- âœ… ä¸ä¼šå‡ºç° "extra_pos2d is not set" é”™è¯¯
- âœ… å¼€ç®±å³ç”¨ï¼Œé›¶é…ç½®

## ğŸ“ æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒè„šæœ¬
- `trainer/train_hf_lora.py` - è®­ç»ƒè„šæœ¬ï¼ˆ319 è¡Œï¼‰
- `scripts/inference_hf_lora.py` - æ¨ç†è„šæœ¬ï¼ˆ375 è¡Œï¼‰

### æµ‹è¯•è„šæœ¬
- `scripts/test_pos2d_handling.py` - pos2d å•å…ƒæµ‹è¯•ï¼ˆ120 è¡Œï¼‰
- `scripts/validate_inference_setup.py` - å®Œæ•´éªŒè¯è„šæœ¬ï¼ˆ420 è¡Œï¼‰
- `scripts/test_inference.sh` - Bash å¿«é€Ÿæµ‹è¯•ï¼ˆ56 è¡Œï¼‰

### æ–‡æ¡£
- `docs/INFERENCE_GUIDE.md` - æ¨ç†è¯¦ç»†æŒ‡å—ï¼ˆ448 è¡Œï¼‰
- `docs/TRAIN_HF_LORA_USAGE.md` - è®­ç»ƒä½¿ç”¨æ–‡æ¡£ï¼ˆ280 è¡Œï¼‰
- `docs/POS2D_IMPLEMENTATION_SUMMARY.md` - pos2d å®ç°æ€»ç»“ï¼ˆ350 è¡Œï¼‰
- `docs/QUICK_START_LORA.md` - å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆ380 è¡Œï¼‰
- `COMPLETION_SUMMARY.md` - æœ¬æ€»ç»“æ–‡æ¡£

### æ›´æ–°æ–‡æ¡£
- `README.md` - ä¸»æ–‡æ¡£ï¼ˆå·²æ›´æ–° HuggingFace + LoRA éƒ¨åˆ†ï¼‰

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### è®­ç»ƒ
```bash
torchrun --nproc_per_node 8 trainer/train_hf_lora.py \
  --base_model Qwen/Qwen2-0.5B-Instruct \
  --data_path dataset/pretrain_hq_split.jsonl \
  --lora_rank 8 \
  --batch_size 4 \
  --batch_by_samples \
  --max_branches_per_sample 16 \
  --min_branches_per_sample 1 \
  --rope_2d_ratio 0.5 \
  --epochs 3 \
  --ddp
```

### æ¨ç†
```bash
# äº¤äº’å¼å¯¹è¯
python scripts/inference_hf_lora.py \
  --base_model Qwen/Qwen2-0.5B-Instruct \
  --lora_path out/lora/qwen2_parallel_lora_hf_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --mode chat

# å•æ¬¡ç”Ÿæˆ
python scripts/inference_hf_lora.py \
  --base_model Qwen/Qwen2-0.5B-Instruct \
  --lora_path out/lora/qwen2_parallel_lora_hf_final.pth \
  --lora_rank 8 \
  --mode generate \
  --prompt "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
```

### Python API
```python
from scripts.inference_hf_lora import load_model_with_lora, generate_text

# åŠ è½½æ¨¡å‹ï¼ˆè‡ªåŠ¨å¤„ç† pos2dï¼‰
model, tokenizer, patch_rope = load_model_with_lora(
    base_model="Qwen/Qwen2-0.5B-Instruct",
    lora_path="out/lora/qwen2_parallel_lora_hf_final.pth",
    lora_rank=8,
    rope_2d_ratio=0.5,
)

# ç”Ÿæˆï¼ˆè‡ªåŠ¨å¤„ç† pos2dï¼‰
response = generate_text(model, tokenizer, "ä½ å¥½")
print(response)
```

## âš ï¸ é‡è¦æç¤º

### âœ… å·²è‡ªåŠ¨å¤„ç†ï¼ˆæ— éœ€å…³å¿ƒï¼‰
1. âœ… **pos2d è‡ªåŠ¨æ³¨å…¥**ï¼šæ¨ç†è„šæœ¬å·²è‡ªåŠ¨å¤„ç†
2. âœ… **prepare_inputs_for_generation é‡å†™**ï¼šæ¯æ¬¡ç”Ÿæˆå‰è‡ªåŠ¨è°ƒç”¨ `set_rope_pos2d`
3. âœ… **å¢é‡ç”Ÿæˆ**ï¼šæ¯æ­¥è‡ªåŠ¨æ›´æ–° pos2d

### âš ï¸ å¿…é¡»æ³¨æ„
1. **å‚æ•°ä¸€è‡´æ€§**ï¼š
   - `--lora_rank` è®­ç»ƒå’Œæ¨ç†å¿…é¡»ä¸€è‡´
   - `--rope_2d_ratio` è®­ç»ƒå’Œæ¨ç†å¿…é¡»ä¸€è‡´
   - è®­ç»ƒç”¨äº† `--patch_rope`ï¼Œæ¨ç†ä¹Ÿå¿…é¡»ç”¨ï¼ˆé»˜è®¤å¯ç”¨ï¼‰

2. **æ•°æ®æ ¼å¼**ï¼š
   - è®­ç»ƒæ•°æ®å¿…é¡»æ˜¯ Parallel æ ¼å¼ï¼ˆ`main` + `branches`ï¼‰
   - ä¸æ”¯æŒæ ‡å‡† SFT æ ¼å¼

3. **æ˜¾å­˜ç®¡ç†**ï¼š
   - æ ¹æ®æ˜¾å­˜è°ƒæ•´ `--batch_size` å’Œ `--accumulation_steps`
   - ä½¿ç”¨ `--dtype bfloat16` ä¼˜åŒ–æ˜¾å­˜ä½¿ç”¨

## ğŸ§ª æµ‹è¯•éªŒè¯

```bash
# pos2d å•å…ƒæµ‹è¯•
python scripts/test_pos2d_handling.py

# å®Œæ•´ç³»ç»ŸéªŒè¯
python scripts/validate_inference_setup.py

# å¿«é€Ÿæ¨ç†æµ‹è¯•
bash scripts/test_inference.sh Qwen/Qwen2-0.5B-Instruct out/lora/qwen2_parallel_lora_hf_final.pth 8
```

## ğŸ“š è¯¦ç»†æ–‡æ¡£é“¾æ¥

- ğŸš€ [å¿«é€Ÿå¼€å§‹æŒ‡å—](docs/QUICK_START_LORA.md)
- ğŸ” [æ¨ç†è¯¦ç»†æŒ‡å—](docs/INFERENCE_GUIDE.md)
- ğŸ“– [è®­ç»ƒä½¿ç”¨æ–‡æ¡£](docs/TRAIN_HF_LORA_USAGE.md)
- ğŸ› ï¸ [pos2d å®ç°æ€»ç»“](docs/POS2D_IMPLEMENTATION_SUMMARY.md)
- ğŸ“˜ [ä¸»æ–‡æ¡£](README.md)

## âœ¨ æŠ€æœ¯äº®ç‚¹

1. **æ— ç¼é›†æˆ HuggingFace ç”Ÿæ€**
   - æ”¯æŒæ‰€æœ‰ `AutoModelForCausalLM` æ¨¡å‹
   - è‡ªåŠ¨åº”ç”¨ 2D RoPE åˆ°ä»»æ„æ¨¡å‹
   - ä¿ç•™åŸæ¨¡å‹çš„æ‰€æœ‰èƒ½åŠ›

2. **é«˜æ•ˆ LoRA å¾®è°ƒ**
   - åªè®­ç»ƒ 0.1%-1% çš„å‚æ•°
   - æ˜¾å­˜å‹å¥½ï¼Œæ”¯æŒå¤§æ¨¡å‹å¾®è°ƒ
   - å¿«é€Ÿè¿­ä»£ï¼Œæ— éœ€å…¨å‚æ•°è®­ç»ƒ

3. **2D RoPE åˆ›æ–°**
   - æ”¯æŒ branch + time äºŒç»´ä½ç½®ç¼–ç 
   - é€‚é…å¹¶è¡Œæ•°æ®è®­ç»ƒ
   - è‡ªåŠ¨è®¡ç®—é¢‘ç‡å¯¹åˆ†é…

4. **pos2d è‡ªåŠ¨å¤„ç†**
   - é€æ˜çš„ pos2d æ³¨å…¥æœºåˆ¶
   - æ— éœ€ç”¨æˆ·å¹²é¢„
   - å®Œç¾å…¼å®¹å¢é‡ç”Ÿæˆ

5. **å®Œå–„çš„æ–‡æ¡£å’Œæµ‹è¯•**
   - 4 ä»½è¯¦ç»†æ–‡æ¡£
   - 3 ä¸ªæµ‹è¯•è„šæœ¬
   - å…¨æµç¨‹éªŒè¯

## ğŸ‰ æ€»ç»“

æ‰€æœ‰ç”¨æˆ·éœ€æ±‚å·²å®Œæˆï¼š
- âœ… åŠ è½½ç°æœ‰ HuggingFace æ¨¡å‹
- âœ… æŒ‰ç…§è®¾è®¡ä¿®æ”¹æ¨¡å‹çš„ RoPEï¼ˆ2D RoPEï¼‰
- âœ… æ·»åŠ  LoRA è¿›è¡Œå¾®è°ƒ
- âœ… ä½¿ç”¨ Parallel æ•°æ®æ ¼å¼è®­ç»ƒ
- âœ… å®Œæ•´çš„æ¨ç†æµç¨‹
- âœ… è§£å†³ GPT-5 å‘ç°çš„ pos2d é—®é¢˜
- âœ… è¯¦ç»†çš„æ–‡æ¡£å’Œæµ‹è¯•

ç³»ç»Ÿå·²ç»è¿‡å®Œæ•´éªŒè¯ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼
