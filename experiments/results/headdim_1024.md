# Head Dimension 消融实验结果 (1024 模型)

**实验日期**: 2026-02-12
**模型规模**: ~270M 参数 (hidden_size=1024, 24 layers)
**训练数据**: 1,024,000 样本 (~250M tokens)

## 实验设计

### 目标

验证最优 `rope_2d_ratio` 是否随 `head_dim` 变化。在固定 `hidden_size=1024` 的前提下，通过改变 `num_heads` 来调整每个 head 的维度和可用频率对数量。

### 配置对比

| 配置 | num_heads | head_dim | kv_heads | 频率对数 | rope=0.5 branch对 | rope=1.0 branch对 |
|------|-----------|----------|----------|----------|-------------------|-------------------|
| h8   | 8         | 128      | 2        | 64       | 32                | 64                |
| h16  | 16        | 64       | 4        | 32       | 16                | 32                |
| h32  | 32        | 32       | 8        | 16       | 8                 | 16                |

### 实验变量

- **rope_2d_ratio**: 0, 0.25, 0.5, 0.75, 1.0（5 个值）
- **训练分支配置**: fixed1（单分支）、1-15（随机 1-15 分支）
- **评估分支数**: 1, 2, 4, 8, 16, 24, 32, 48, 64

**总计**: 3 个 head 配置 × 5 个 ratio × 2 个训练配置 = 30 组训练

## 核心结果对比

### 1. 训练配置 1-15 + eval_branch=1（单分支质量）

| rope_ratio | h8 (d=128) | h16 (d=64) | h32 (d=32) | 最优 |
|------------|------------|------------|------------|------|
| 0          | 3.6205     | 3.2204     | 3.2325     | h16  |
| 0.25       | 3.7039     | 3.3023     | 3.1461     | h32  |
| 0.5        | **2.9121** | **2.8506** | **2.9181** | h16  |
| 0.75       | 3.0350     | **2.7274** | **2.7188** | h32  |
| 1.0        | 3.0524     | 2.7699     | **2.6716** | h32  |

**观察**：
- rope=0.5: 三个配置都接近，h16 略优
- rope=0.75: h16 和 h32 几乎持平（差 0.009）
- **rope=1.0: head_dim 越小，单分支质量越好**（h32 > h16 > h8）

### 2. 训练配置 1-15 + eval_branch=64（并行扩展能力）

| rope_ratio | h8 (d=128) | h16 (d=64) | h32 (d=32) | 最优 |
|------------|------------|------------|------------|------|
| 0          | 5.7616     | 5.6485     | 5.7790     | h16  |
| 0.25       | 5.1138     | 5.2793     | 5.3235     | h8   |
| 0.5        | 4.3226     | 4.6163     | 4.8829     | h8   |
| 0.75       | 3.7312     | 3.3131     | 3.5203     | h16  |
| 1.0        | **2.9556** | **2.8152** | **2.9924** | h16  |

**观察**：
- rope ≤ 0.5: h8 更好（更多频率对帮助分支区分）
- rope ≥ 0.75: h16 最优
- **rope=1.0: h16 达到 2.82，优于 h8 的 2.96 和 h32 的 3.00**

### 3. 训练配置 1-15 的扩展曲线（branch=1 → 64）

| 配置      | b=1   | b=2   | b=4   | b=8   | b=16  | b=24  | b=32  | b=48  | b=64  | 波动  |
|-----------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|
| h8, r=1.0 | 3.05  | 2.97  | 2.93  | 2.92  | 2.92  | 2.93  | 2.93  | 2.94  | 2.96  | 0.13  |
| h16, r=1.0| 2.77  | 2.76  | 2.75  | 2.75  | 2.75  | 2.76  | 2.77  | 2.79  | 2.82  | **0.07** |
| h32, r=1.0| **2.67** | 2.66  | 2.66  | 2.65  | 2.66  | 2.77  | 2.84  | 2.91  | 3.00  | 0.35  |
| h16, r=0.75| 2.73 | 2.71  | 2.70  | 2.72  | 2.74  | 2.87  | 3.03  | 3.20  | 3.31  | 0.61  |
| h8, r=0.75| 3.04  | 2.94  | 2.92  | 2.90  | 2.92  | 3.18  | 3.33  | 3.60  | 3.73  | 0.83  |

**关键发现**：
- **h16 + rope=1.0 最平坦**：从 2.77 到 2.82，波动仅 0.07
- **h32 + rope=1.0 单分支最好（2.67），但 64 分支时退化到 3.00**
- **h8 频率对虽多，但模型容量不足以充分利用**

### 4. 训练配置 fixed1 + eval_branch=1（标准 Transformer 基准）

| rope_ratio | h8 (d=128) | h16 (d=64) | h32 (d=32) | 差异范围 |
|------------|------------|------------|------------|----------|
| 0          | 2.4194     | 2.4285     | 2.4036     | 0.025    |
| 0.25       | 2.4375     | 2.3935     | 2.4328     | 0.044    |
| 0.5        | 2.4182     | **2.3817** | 2.4491     | 0.067    |
| 0.75       | **2.3948** | 2.4590     | **2.3769** | 0.082    |
| 1.0        | 2.4294     | 2.4802     | 2.4351     | 0.051    |

**观察**：
- fixed1 单分支训练下，所有配置都收敛到 ~2.4，差异极小
- rope=0.5 在 h16 上略优（2.38），但与 h32 的 rope=0.75（2.38）持平
- 说明对于单分支标准 Transformer，head_dim 影响不大

## 完整实验数据表

### h8 (head_dim=128, 64 频率对)

#### 训练 1-15

| rope | eval_b | loss  | ppl    | rope | eval_b | loss  | ppl    |
|------|--------|-------|--------|------|--------|-------|--------|
| 0    | 1      | 3.621 | 37.36  | 0.5  | 1      | 2.912 | 18.39  |
| 0    | 8      | 3.876 | 48.25  | 0.5  | 8      | 3.006 | 20.20  |
| 0    | 16     | 4.925 | 137.62 | 0.5  | 16     | 3.184 | 24.14  |
| 0    | 64     | 5.762 | 317.85 | 0.5  | 64     | 4.323 | 75.38  |
| 0.25 | 1      | 3.704 | 40.60  | 0.75 | 1      | 3.035 | 20.80  |
| 0.25 | 8      | 4.342 | 76.88  | 0.75 | 8      | 2.904 | 18.24  |
| 0.25 | 16     | 4.571 | 96.65  | 0.75 | 16     | 2.920 | 18.54  |
| 0.25 | 64     | 5.114 | 166.29 | 0.75 | 64     | 3.731 | 41.73  |
| 1.0  | 1      | 3.052 | 21.17  |      |        |       |        |
| 1.0  | 8      | 2.922 | 18.58  |      |        |       |        |
| 1.0  | 16     | 2.917 | 18.48  |      |        |       |        |
| 1.0  | 64     | 2.956 | 19.21  |      |        |       |        |

#### 训练 fixed1

| rope | eval_b | loss  | ppl    | rope | eval_b | loss  | ppl    |
|------|--------|-------|--------|------|--------|-------|--------|
| 0    | 1      | 2.419 | 11.24  | 0.75 | 1      | 2.395 | 10.97  |
| 0    | 64     | 5.884 | 359.10 | 0.75 | 64     | 5.720 | 304.96 |
| 1.0  | 1      | 2.429 | 11.35  |      |        |       |        |
| 1.0  | 64     | 5.554 | 258.20 |      |        |       |        |

### h16 (head_dim=64, 32 频率对) - 参考基准

详见 `branch_1024.md`（之前的 1024 模型消融实验结果）

### h32 (head_dim=32, 16 频率对)

#### 训练 1-15

| rope | eval_b | loss  | ppl    | rope | eval_b | loss  | ppl    |
|------|--------|-------|--------|------|--------|-------|--------|
| 0    | 1      | 3.233 | 25.34  | 0.5  | 1      | 2.918 | 18.51  |
| 0    | 8      | 5.282 | 196.71 | 0.5  | 8      | 3.024 | 20.57  |
| 0    | 16     | 5.596 | 269.22 | 0.5  | 16     | 3.201 | 24.56  |
| 0    | 64     | 5.779 | 323.44 | 0.5  | 64     | 4.883 | 132.01 |
| 0.25 | 1      | 3.146 | 23.24  | 0.75 | 1      | 2.719 | 15.16  |
| 0.25 | 8      | 3.970 | 52.99  | 0.75 | 8      | 2.735 | 15.41  |
| 0.25 | 16     | 4.511 | 91.03  | 0.75 | 16     | 2.829 | 16.93  |
| 0.25 | 64     | 5.324 | 205.09 | 0.75 | 64     | 3.520 | 33.80  |
| 1.0  | 1      | 2.672 | 14.46  |      |        |       |        |
| 1.0  | 8      | 2.652 | 14.18  |      |        |       |        |
| 1.0  | 16     | 2.661 | 14.30  |      |        |       |        |
| 1.0  | 64     | 2.992 | 19.93  |      |        |       |        |

#### 训练 fixed1

| rope | eval_b | loss  | ppl    | rope | eval_b | loss  | ppl    |
|------|--------|-------|--------|------|--------|-------|--------|
| 0    | 1      | 2.404 | 11.06  | 0.75 | 1      | 2.377 | 10.77  |
| 0    | 64     | 5.966 | 389.97 | 0.75 | 64     | 5.885 | 359.53 |
| 1.0  | 1      | 2.435 | 11.42  |      |        |       |        |
| 1.0  | 64     | 5.809 | 333.42 |      |        |       |        |

## 关键结论

### 1. head_dim=64 (h16) 是当前模型规模的最优选择

- **rope=1.0, 训练 1-15**:
  - 单分支: 2.77（略高于 h32 的 2.67）
  - 64 分支: **2.82**（最优，优于 h8 的 2.96 和 h32 的 3.00）
  - **波动最小**: 0.07（h8 是 0.13，h32 是 0.35）

### 2. 频率对数量的权衡

- **过多（h8, 64 对）**: 模型容量（272M 参数，8 个 head）不足以充分利用，导致单分支质量下降
- **过少（h32, 16 对）**: 单分支质量最好，但高分支时频率对不足，扩展性受限
- **适中（h16, 32 对）**: 在当前模型规模下达到最佳平衡

### 3. rope_2d_ratio 的最优值随 head_dim 变化

**对于并行解码（branch=64）：**
- h8: rope=1.0 最优（2.96），但 rope=0.75 也可接受（3.73）
- h16: rope=1.0 明显最优（2.82），rope=0.75 退化到 3.31
- h32: rope=1.0 最优（3.00），rope=0.75 退化到 3.52

**规律**：频率对越少，越需要高 rope_2d_ratio 才能保持高分支扩展性

### 4. 对更大模型的推论

如果扩展到 1B+ 参数：
- head_dim=128 的优势可能显现（更多参数能利用 64 个频率对）
- 但 head_dim=64 可能仍然是性价比最高的选择
- 需要实验验证

### 5. 最终推荐配置（272M 模型）

**并行解码场景（目标 16-64 分支）：**
```
hidden_size: 1024
num_heads: 16 (head_dim=64)
rope_2d_ratio: 1.0
训练分支: 1-15
```

**单分支优先场景：**
```
hidden_size: 1024
num_heads: 32 (head_dim=32)
rope_2d_ratio: 0.75 或 1.0
训练分支: 1-15
```

## 技术细节

- 训练样本: 1,024,000
- 验证样本: 200,000
- Batch size:
  - fixed1: batch=4, accum=2 (效果 batch=8)
  - 1-15: batch=1, accum=1 (多分支显存压力大)
- 优化器: AdamW
- 学习率: 5e-5
- GQA ratio: 4:1 (head:kv_head)
- 位置编码: Interleaved 2D RoPE
- Attention: PyTorch SDPA

## 相关文件

- 原始结果 CSV:
  - `scripts/logs/ablation_1024_h8_d128/results.csv`
  - `scripts/logs/ablation_1024_h16_d64/results.csv` (即原 1024 模型)
  - `scripts/logs/ablation_1024_h32_d32/results.csv`
- 训练脚本: `scripts/parameters/run_ablation_headdim.sh`
- 可视化: `Experiments/Figures/branch_ablation/1024/`

---

**实验完成时间**: 2026-02-13 00:00:00（预计）
**总训练时长**: ~24 小时（30 组实验，8× H20 GPUs）
