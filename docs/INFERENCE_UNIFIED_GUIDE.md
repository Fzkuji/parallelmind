# HuggingFace + LoRA æ¨ç†ç»Ÿä¸€æŒ‡å—

## æ¦‚è¿°

æœ¬æŒ‡å—æä¾› ParallelMind é¡¹ç›®çš„æ¨ç†è„šæœ¬ä½¿ç”¨è¯´æ˜ã€‚æˆ‘ä»¬æœ‰ä¸‰ä¸ªæ¨ç†è„šæœ¬ï¼Œé’ˆå¯¹ä¸åŒåœºæ™¯ä¼˜åŒ–ã€‚

## å¿«é€Ÿå†³ç­–

**æˆ‘è¯¥ç”¨å“ªä¸ªè„šæœ¬ï¼Ÿ**

```
ä½ æƒ³åšä»€ä¹ˆï¼Ÿ
â”‚
â”œâ”€ æµ‹è¯•å•ä¸ªé—®é¢˜ / äº¤äº’å¼å¯¹è¯
â”‚  â””â”€ ä½¿ç”¨ï¼šinference_hf_lora.py
â”‚
â”œâ”€ æ¨ç†å‡ ä¸ªåˆ°å‡ ç™¾ä¸ªé—®é¢˜
â”‚  â”œâ”€ ç›´æ¥è¾“å…¥é—®é¢˜
â”‚  â”‚  â””â”€ ä½¿ç”¨ï¼šparallel_generate.py --prompts "é—®é¢˜1" "é—®é¢˜2" ...
â”‚  â”œâ”€ ä»æ–‡æœ¬æ–‡ä»¶è¯»å–
â”‚  â”‚  â””â”€ ä½¿ç”¨ï¼šparallel_generate.py --prompts_file questions.txt
â”‚  â””â”€ ä» JSONL è¯»å–
â”‚     â””â”€ ä½¿ç”¨ï¼šparallel_generate.py --data_path dataset/test.jsonl
â”‚
â””â”€ å¤§è§„æ¨¡æ¨ç†ï¼ˆ10000+ æ ·æœ¬ï¼‰
   â””â”€ ä½¿ç”¨ï¼šparallel_inference_hf_lora.py --data_path dataset/large.jsonl
```

---

## æ¨èï¼š`parallel_generate.py`ï¼ˆä¸»è¦æ¨ç†è„šæœ¬ï¼‰

### é€‚ç”¨åœºæ™¯

- âœ… ç›´æ¥è¾“å…¥é—®é¢˜åˆ—è¡¨ï¼ˆå‘½ä»¤è¡Œæˆ–æ–‡æœ¬æ–‡ä»¶ï¼‰
- âœ… ä¸­å°è§„æ¨¡æ¨ç†ï¼ˆ1-1000 ä¸ªé—®é¢˜ï¼‰
- âœ… éœ€è¦çœ‹åˆ°ç”Ÿæˆè¿‡ç¨‹ï¼ˆstreamingï¼‰
- âœ… çµæ´»çš„è¾“å…¥æ–¹å¼
- âœ… å¿«é€Ÿæµ‹è¯•å’Œè°ƒè¯•

### ä½¿ç”¨æ–¹å¼ 1ï¼šç›´æ¥è¾“å…¥é—®é¢˜ï¼ˆæœ€å¸¸ç”¨ï¼‰

```bash
# å• GPU
python scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --prompts "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½" "è®²è§£æ·±åº¦å­¦ä¹ " "ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ "

# å¤š GPU
torchrun --nproc_per_node 8 scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --prompts "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½" "è®²è§£æ·±åº¦å­¦ä¹ " "ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ "
```

### ä½¿ç”¨æ–¹å¼ 2ï¼šä»æ–‡æœ¬æ–‡ä»¶è¯»å–

åˆ›å»º `questions.txt`ï¼š
```text
ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½
è®²è§£æ·±åº¦å­¦ä¹ 
ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ 
è‡ªç„¶è¯­è¨€å¤„ç†çš„åº”ç”¨
è®¡ç®—æœºè§†è§‰æŠ€æœ¯
```

è¿è¡Œæ¨ç†ï¼š
```bash
python scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --prompts_file questions.txt
```

### ä½¿ç”¨æ–¹å¼ 3ï¼šä» JSONL è¯»å–

å¯¹äº Parallel æ ¼å¼æ•°æ®ï¼š
```bash
python scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --data_path dataset/test.jsonl \
  --max_branches_per_sample 8 \
  --batch_by_samples \
  --batch_size 16
```

### ä¸»è¦å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--hf_base_model` | HuggingFace æ¨¡å‹è·¯å¾„ | - |
| `--lora_path` | LoRA æƒé‡è·¯å¾„ | - |
| `--lora_rank` | LoRA rank | 8 |
| `--rope_2d_ratio` | 2D RoPE æ¯”ä¾‹ | 0.5 |
| `--prompts` | ç›´æ¥è¾“å…¥é—®é¢˜ï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ | - |
| `--prompts_file` | é—®é¢˜æ–‡æœ¬æ–‡ä»¶ | - |
| `--data_path` | JSONL æ•°æ®æ–‡ä»¶ | - |
| `--max_new_tokens` | æœ€å¤§ç”Ÿæˆé•¿åº¦ | 512 |
| `--temperature` | æ¸©åº¦ | 0.7 |
| `--stream` | æµå¼è¾“å‡º | True |
| `--no_patch_rope` | ç¦ç”¨ 2D RoPE | False |

---

## å•æ¡æ¨ç†ï¼š`inference_hf_lora.py`

### é€‚ç”¨åœºæ™¯

- âœ… æµ‹è¯•å•ä¸ªé—®é¢˜
- âœ… äº¤äº’å¼å¯¹è¯
- âœ… å¿«é€ŸéªŒè¯æ¨¡å‹æ•ˆæœ

### åŸºæœ¬ä½¿ç”¨

```bash
# å•æ¡æ¨ç†
python scripts/inference_hf_lora.py \
  --base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --prompt "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"

# äº¤äº’å¼å¯¹è¯
python scripts/inference_hf_lora.py \
  --base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --interactive
```

### ä¸»è¦å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--base_model` | HuggingFace æ¨¡å‹è·¯å¾„ | - |
| `--lora_path` | LoRA æƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰ | None |
| `--lora_rank` | LoRA rank | 8 |
| `--rope_2d_ratio` | 2D RoPE æ¯”ä¾‹ | 0.5 |
| `--prompt` | è¾“å…¥é—®é¢˜ | - |
| `--interactive` | äº¤äº’æ¨¡å¼ | False |
| `--max_new_tokens` | æœ€å¤§ç”Ÿæˆé•¿åº¦ | 512 |
| `--no_patch_rope` | ç¦ç”¨ 2D RoPE | False |

è¯¦ç»†æ–‡æ¡£ï¼š[docs/INFERENCE_GUIDE.md](INFERENCE_GUIDE.md)

---

## å¤§è§„æ¨¡æ¨ç†ï¼š`parallel_inference_hf_lora.py`ï¼ˆå¤‡é€‰ï¼‰

### é€‚ç”¨åœºæ™¯

- âœ… è¶…å¤§è§„æ¨¡æ¨ç†ï¼ˆ10000+ æ ·æœ¬ï¼‰
- âœ… éœ€è¦æœ€é«˜ååé‡
- âœ… å·²æœ‰ JSONL æ•°æ®é›†

### é™åˆ¶

- âŒ ä»…æ”¯æŒ JSONL æ–‡ä»¶è¾“å…¥
- âŒ ä¸æ”¯æŒç›´æ¥å‘½ä»¤è¡Œè¾“å…¥é—®é¢˜
- âŒ ä¸æ”¯æŒå®æ—¶è¾“å‡º

### åŸºæœ¬ä½¿ç”¨

```bash
# å• GPU
python scripts/parallel_inference_hf_lora.py \
  --base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --data_path dataset/test_10k.jsonl \
  --out_path out/results_10k.jsonl \
  --batch_size 16 \
  --batch_by_samples

# å¤š GPUï¼ˆæ¨èï¼‰
torchrun --nproc_per_node 8 scripts/parallel_inference_hf_lora.py \
  --base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --lora_rank 8 \
  --rope_2d_ratio 0.5 \
  --data_path dataset/test_10k.jsonl \
  --out_path out/results_10k.jsonl \
  --batch_size 16 \
  --batch_by_samples \
  --max_branches_per_sample 12
```

è¯¦ç»†æ–‡æ¡£ï¼š[docs/PARALLEL_INFERENCE_GUIDE.md](PARALLEL_INFERENCE_GUIDE.md)

---

## è„šæœ¬å¯¹æ¯”

| ç‰¹æ€§ | parallel_generate.py | parallel_inference_hf_lora.py | inference_hf_lora.py |
|------|---------------------|------------------------------|---------------------|
| **æ¨èåº¦** | â­â­â­â­â­ ä¸»æ¨ | â­â­â­ å¤‡é€‰ | â­â­â­â­ å•ç”¨ |
| **è¾“å…¥æ–¹å¼** | å‘½ä»¤è¡Œ/æ–‡æœ¬/JSONL | ä»… JSONL | å‘½ä»¤è¡Œ/äº¤äº’ |
| **å¤š GPU** | âœ… | âœ… | âŒ |
| **æ‰¹é‡æ¨ç†** | âœ… | âœ… | âŒ |
| **å®æ—¶è¾“å‡º** | âœ… | âŒ | âœ… |
| **ååé‡** | é«˜ | æœ€é«˜ | - |
| **æ˜“ç”¨æ€§** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ |
| **çµæ´»æ€§** | â­â­â­â­â­ | â­â­ | â­â­â­â­ |

---

## å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹

```bash
# å•æ¡æµ‹è¯•
python scripts/inference_hf_lora.py \
  --base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --prompt "ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"
```

### åœºæ™¯ 2ï¼šæ‰¹é‡ç”Ÿæˆå›å¤ï¼ˆ10-100 ä¸ªé—®é¢˜ï¼‰

```bash
# åˆ›å»º questions.txt åŒ…å«ä½ çš„é—®é¢˜
python scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --prompts_file questions.txt
```

### åœºæ™¯ 3ï¼šè¯„ä¼°æ¨¡å‹ï¼ˆ1000+ æµ‹è¯•æ ·æœ¬ï¼‰

```bash
# ä½¿ç”¨ JSONL æµ‹è¯•é›†
python scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --data_path dataset/test_1k.jsonl \
  --batch_size 16
```

### åœºæ™¯ 4ï¼šå¤§è§„æ¨¡ç”Ÿæˆï¼ˆ10000+ æ ·æœ¬ï¼‰

```bash
# å¤š GPU é«˜ååé‡
torchrun --nproc_per_node 8 scripts/parallel_inference_hf_lora.py \
  --base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --data_path dataset/test_10k.jsonl \
  --out_path out/results_10k.jsonl \
  --batch_size 8 \
  --batch_by_samples
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. é€‰æ‹©åˆé€‚çš„è„šæœ¬

- **< 100 é—®é¢˜** â†’ `parallel_generate.py`ï¼ˆç›´æ¥è¾“å…¥æˆ–æ–‡æœ¬æ–‡ä»¶ï¼‰
- **100-1000 é—®é¢˜** â†’ `parallel_generate.py`ï¼ˆJSONLï¼‰
- **> 10000 é—®é¢˜** â†’ `parallel_inference_hf_lora.py`

### 2. æ‰¹é‡å¤§å°è°ƒæ•´

```bash
# æ˜¾å­˜å……è¶³
--batch_size 32

# æ˜¾å­˜ä¸è¶³
--batch_size 4
```

### 3. å¤š GPU åŠ é€Ÿ

```bash
# ä½¿ç”¨æ‰€æœ‰å¯ç”¨ GPU
torchrun --nproc_per_node $(nvidia-smi -L | wc -l) scripts/parallel_generate.py ...
```

### 4. åŠ¨æ€ branch æ¨¡å¼

```bash
# æ›´é«˜æ•ˆçš„æ˜¾å­˜åˆ©ç”¨
--max_branches_per_sample 16 \
--min_branches_per_sample 1 \
--batch_by_samples
```

---

## å¸¸è§é—®é¢˜

### Q1: æˆ‘åªæƒ³è¾“å…¥å‡ ä¸ªé—®é¢˜ï¼Œè¯¥ç”¨å“ªä¸ªï¼Ÿ

**A**: ä½¿ç”¨ `parallel_generate.py` + `--prompts`

```bash
python scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --prompts "é—®é¢˜1" "é—®é¢˜2" "é—®é¢˜3"
```

### Q2: æˆ‘æœ‰ä¸€ä¸ªåŒ…å«å¾ˆå¤šé—®é¢˜çš„æ–‡æœ¬æ–‡ä»¶ï¼Œè¯¥ç”¨å“ªä¸ªï¼Ÿ

**A**: ä½¿ç”¨ `parallel_generate.py` + `--prompts_file`

```bash
python scripts/parallel_generate.py \
  --hf_base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --prompts_file my_questions.txt
```

### Q3: æˆ‘æœ‰ 10000+ æ ·æœ¬çš„ JSONL æ•°æ®é›†ï¼Œè¯¥ç”¨å“ªä¸ªï¼Ÿ

**A**: ä½¿ç”¨ `parallel_inference_hf_lora.py`

```bash
torchrun --nproc_per_node 8 scripts/parallel_inference_hf_lora.py \
  --base_model Qwen/Qwen2.5-14B-Instruct \
  --lora_path out/lora/qwen2_lora_final.pth \
  --data_path dataset/large.jsonl \
  --out_path out/results.jsonl
```

### Q4: å¯ä»¥ä¸ç”¨ LoRA å—ï¼Ÿ

**A**: å¯ä»¥ï¼Œä¸æŒ‡å®š `--lora_path` å³å¯ä½¿ç”¨çº¯åŸºç¡€æ¨¡å‹ã€‚

### Q5: å¦‚ä½•ç¦ç”¨ 2D RoPEï¼Ÿ

**A**: æ·»åŠ  `--no_patch_rope` å‚æ•°ã€‚

---

## ç›¸å…³æ–‡æ¡£

- ğŸ“š [å•æ¡æ¨ç†è¯¦ç»†æŒ‡å—](INFERENCE_GUIDE.md)
- ğŸ“š [å¤§è§„æ¨¡æ¨ç†æŒ‡å—](PARALLEL_INFERENCE_GUIDE.md)
- ğŸ“š [Claude ä¸ GPT å…±è¯†](CLAUDE_GPT_CONSENSUS.md)
- ğŸ“š [è®­ç»ƒä½¿ç”¨æ–‡æ¡£](TRAIN_HF_LORA_USAGE.md)
- ğŸ“š [å¿«é€Ÿå¼€å§‹](QUICK_START_LORA.md)
- ğŸ“š [pos2d æŠ€æœ¯ç»†èŠ‚](POS2D_IMPLEMENTATION_SUMMARY.md)

---

## æ€»ç»“

**é»˜è®¤æ¨è**ï¼šä½¿ç”¨ `parallel_generate.py`

- âœ… æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼ï¼ˆå‘½ä»¤è¡Œã€æ–‡æœ¬æ–‡ä»¶ã€JSONLï¼‰
- âœ… å®æ—¶çœ‹åˆ°ç”Ÿæˆè¿‡ç¨‹
- âœ… æ”¯æŒå¤š GPU
- âœ… æœ€çµæ´»æ˜“ç”¨

**é€‚åˆ 90% çš„ä½¿ç”¨åœºæ™¯ï¼**
