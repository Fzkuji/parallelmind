#!/usr/bin/env python3
"""
éªŒè¯å®Œæ•´çš„ HuggingFace + LoRA + 2D RoPE æ¨ç†æµç¨‹
æ£€æŸ¥æ‰€æœ‰å…³é”®ç»„ä»¶æ˜¯å¦æ­£ç¡®é›†æˆ
"""
import os
import sys
import argparse

root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if root_path not in sys.path:
    sys.path.insert(0, root_path)


def check_imports():
    """æ£€æŸ¥æ‰€æœ‰å¿…è¦çš„å¯¼å…¥"""
    print("=" * 80)
    print("æ£€æŸ¥ 1: éªŒè¯å¿…è¦æ¨¡å—å¯¼å…¥")
    print("=" * 80)

    try:
        import torch
        print("âœ“ torch")
    except ImportError as e:
        print(f"âœ— torch: {e}")
        return False

    try:
        from transformers import AutoTokenizer, AutoModelForCausalLM
        print("âœ“ transformers")
    except ImportError as e:
        print(f"âœ— transformers: {e}")
        return False

    try:
        from model.model_lora import apply_lora, load_lora, save_lora
        print("âœ“ model.model_lora")
    except ImportError as e:
        print(f"âœ— model.model_lora: {e}")
        return False

    try:
        from parallel.columnar import (
            patch_model_with_interleaved_2d_rope,
            set_rope_pos2d,
            _find_rotary_holder,
        )
        print("âœ“ parallel.columnar")
    except ImportError as e:
        print(f"âœ— parallel.columnar: {e}")
        return False

    try:
        from scripts.inference_hf_lora import (
            load_model_with_lora,
            generate_text,
            _prepare_pos2d,
            _inject_pos2d_hook,
        )
        print("âœ“ scripts.inference_hf_lora")
    except ImportError as e:
        print(f"âœ— scripts.inference_hf_lora: {e}")
        return False

    print("\næ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\n")
    return True


def check_training_script():
    """æ£€æŸ¥è®­ç»ƒè„šæœ¬æ˜¯å¦å­˜åœ¨ä¸”å¯å¯¼å…¥"""
    print("=" * 80)
    print("æ£€æŸ¥ 2: éªŒè¯è®­ç»ƒè„šæœ¬")
    print("=" * 80)

    train_script = os.path.join(root_path, "trainer", "train_hf_lora.py")
    if not os.path.exists(train_script):
        print(f"âœ— è®­ç»ƒè„šæœ¬ä¸å­˜åœ¨: {train_script}")
        return False

    print(f"âœ“ è®­ç»ƒè„šæœ¬å­˜åœ¨: {train_script}")

    # æ£€æŸ¥å…³é”®å‡½æ•°
    try:
        sys.path.insert(0, os.path.join(root_path, "trainer"))
        import train_hf_lora
        assert hasattr(train_hf_lora, "auto_pair_indices"), "ç¼ºå°‘ auto_pair_indices å‡½æ•°"
        print("âœ“ auto_pair_indices å‡½æ•°å­˜åœ¨")
        assert hasattr(train_hf_lora, "train_epoch"), "ç¼ºå°‘ train_epoch å‡½æ•°"
        print("âœ“ train_epoch å‡½æ•°å­˜åœ¨")
    except Exception as e:
        print(f"âœ— è®­ç»ƒè„šæœ¬æ£€æŸ¥å¤±è´¥: {e}")
        return False

    print("\nè®­ç»ƒè„šæœ¬éªŒè¯æˆåŠŸï¼\n")
    return True


def check_inference_script():
    """æ£€æŸ¥æ¨ç†è„šæœ¬æ˜¯å¦æ­£ç¡®å®ç°"""
    print("=" * 80)
    print("æ£€æŸ¥ 3: éªŒè¯æ¨ç†è„šæœ¬å®ç°")
    print("=" * 80)

    inference_script = os.path.join(root_path, "scripts", "inference_hf_lora.py")
    if not os.path.exists(inference_script):
        print(f"âœ— æ¨ç†è„šæœ¬ä¸å­˜åœ¨: {inference_script}")
        return False

    print(f"âœ“ æ¨ç†è„šæœ¬å­˜åœ¨: {inference_script}")

    # æ£€æŸ¥å…³é”®å‡½æ•°
    from scripts.inference_hf_lora import (
        _prepare_pos2d,
        _inject_pos2d_hook,
        load_model_with_lora,
        generate_text,
        interactive_chat,
    )

    print("âœ“ _prepare_pos2d å‡½æ•°å­˜åœ¨")
    print("âœ“ _inject_pos2d_hook å‡½æ•°å­˜åœ¨")
    print("âœ“ load_model_with_lora å‡½æ•°å­˜åœ¨")
    print("âœ“ generate_text å‡½æ•°å­˜åœ¨")
    print("âœ“ interactive_chat å‡½æ•°å­˜åœ¨")

    # æ£€æŸ¥ _inject_pos2d_hook å®ç°
    import inspect
    source = inspect.getsource(_inject_pos2d_hook)
    assert "prepare_inputs_for_generation" in source, "ç¼ºå°‘ prepare_inputs_for_generation é‡å†™"
    print("âœ“ _inject_pos2d_hook æ­£ç¡®å®ç°äº† prepare_inputs_for_generation é‡å†™")

    assert "set_rope_pos2d" in source, "ç¼ºå°‘ set_rope_pos2d è°ƒç”¨"
    print("âœ“ _inject_pos2d_hook ä¸­è°ƒç”¨äº† set_rope_pos2d")

    print("\næ¨ç†è„šæœ¬éªŒè¯æˆåŠŸï¼\n")
    return True


def check_documentation():
    """æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å®Œæ•´"""
    print("=" * 80)
    print("æ£€æŸ¥ 4: éªŒè¯æ–‡æ¡£å®Œæ•´æ€§")
    print("=" * 80)

    docs = [
        ("README.md", "ä¸»æ–‡æ¡£"),
        ("docs/INFERENCE_GUIDE.md", "æ¨ç†æŒ‡å—"),
        ("docs/TRAIN_HF_LORA_USAGE.md", "è®­ç»ƒä½¿ç”¨æ–‡æ¡£"),
    ]

    all_exist = True
    for doc_path, doc_name in docs:
        full_path = os.path.join(root_path, doc_path)
        if os.path.exists(full_path):
            print(f"âœ“ {doc_name} å­˜åœ¨: {doc_path}")

            # æ£€æŸ¥å…³é”®è¯
            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read()

            if "INFERENCE_GUIDE" in doc_path:
                if "pos2d" in content:
                    print(f"  âœ“ {doc_name} åŒ…å« pos2d è¯´æ˜")
                else:
                    print(f"  âš ï¸  {doc_name} ç¼ºå°‘ pos2d è¯´æ˜")

                if "set_rope_pos2d" in content:
                    print(f"  âœ“ {doc_name} åŒ…å« set_rope_pos2d è¯´æ˜")
                else:
                    print(f"  âš ï¸  {doc_name} ç¼ºå°‘ set_rope_pos2d è¯´æ˜")

        else:
            print(f"âœ— {doc_name} ä¸å­˜åœ¨: {doc_path}")
            all_exist = False

    if all_exist:
        print("\næ–‡æ¡£å®Œæ•´æ€§éªŒè¯æˆåŠŸï¼\n")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ–‡æ¡£ç¼ºå¤±\n")

    return all_exist


def check_pos2d_workflow():
    """æ£€æŸ¥ pos2d å·¥ä½œæµç¨‹"""
    print("=" * 80)
    print("æ£€æŸ¥ 5: éªŒè¯ pos2d å·¥ä½œæµç¨‹")
    print("=" * 80)

    import torch
    from scripts.inference_hf_lora import _prepare_pos2d, _inject_pos2d_hook

    # æµ‹è¯• _prepare_pos2d
    input_ids = torch.randint(0, 1000, (2, 10))
    pos2d = _prepare_pos2d(input_ids)

    assert pos2d.shape == (2, 10, 2), "pos2d å½¢çŠ¶é”™è¯¯"
    print("âœ“ _prepare_pos2d ç”Ÿæˆæ­£ç¡®çš„ pos2d å½¢çŠ¶")

    assert torch.all(pos2d[:, :, 0] == 0), "branch_ids åº”è¯¥å…¨ä¸º 0"
    print("âœ“ branch_ids å…¨ä¸º 0ï¼ˆå•åˆ†æ”¯æ¨ç†ï¼‰")

    expected_time = torch.arange(10).unsqueeze(0).expand(2, -1)
    assert torch.all(pos2d[:, :, 1] == expected_time), "time_ids åº”è¯¥çº¿æ€§é€’å¢"
    print("âœ“ time_ids çº¿æ€§é€’å¢")

    # æµ‹è¯• hook æ³¨å…¥
    class DummyModel:
        def __init__(self):
            self._pos2d_hook_injected = False

        def prepare_inputs_for_generation(self, input_ids, **kwargs):
            return {"input_ids": input_ids}

    model = DummyModel()
    _inject_pos2d_hook(model)

    assert model._pos2d_hook_injected, "hook åº”è¯¥å·²æ³¨å…¥"
    print("âœ“ hook æˆåŠŸæ³¨å…¥åˆ°æ¨¡å‹")

    assert hasattr(model, "_orig_prepare_inputs_for_generation"), "åŸå§‹æ–¹æ³•åº”è¯¥è¢«ä¿å­˜"
    print("âœ“ åŸå§‹ prepare_inputs_for_generation å·²ä¿å­˜")

    print("\npos2d å·¥ä½œæµç¨‹éªŒè¯æˆåŠŸï¼\n")
    return True


def check_file_structure():
    """æ£€æŸ¥é¡¹ç›®æ–‡ä»¶ç»“æ„"""
    print("=" * 80)
    print("æ£€æŸ¥ 6: éªŒè¯é¡¹ç›®æ–‡ä»¶ç»“æ„")
    print("=" * 80)

    required_files = [
        "trainer/train_hf_lora.py",
        "scripts/inference_hf_lora.py",
        "scripts/test_inference.sh",
        "model/model_lora.py",
        "parallel/columnar.py",
        "parallel_data/parallel_dataset.py",
        "parallel_data/parallel_collator.py",
    ]

    all_exist = True
    for file_path in required_files:
        full_path = os.path.join(root_path, file_path)
        if os.path.exists(full_path):
            print(f"âœ“ {file_path}")
        else:
            print(f"âœ— {file_path} ä¸å­˜åœ¨")
            all_exist = False

    if all_exist:
        print("\næ–‡ä»¶ç»“æ„éªŒè¯æˆåŠŸï¼\n")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ–‡ä»¶ç¼ºå¤±\n")

    return all_exist


def print_summary():
    """æ‰“å°ä½¿ç”¨æ‘˜è¦"""
    print("=" * 80)
    print("ä½¿ç”¨æ‘˜è¦")
    print("=" * 80)

    print("\nğŸ“ è®­ç»ƒå‘½ä»¤ç¤ºä¾‹ï¼š")
    print("-" * 80)
    print("""
torchrun --nproc_per_node 8 trainer/train_hf_lora.py \\
  --base_model Qwen/Qwen2-0.5B-Instruct \\
  --data_path dataset/pretrain_hq_split.jsonl \\
  --lora_rank 8 \\
  --batch_size 4 \\
  --batch_by_samples \\
  --max_branches_per_sample 16 \\
  --min_branches_per_sample 1 \\
  --rope_2d_ratio 0.5 \\
  --epochs 3 \\
  --ddp
""".strip())

    print("\nğŸ” æ¨ç†å‘½ä»¤ç¤ºä¾‹ï¼š")
    print("-" * 80)
    print("""
# äº¤äº’å¼å¯¹è¯
python scripts/inference_hf_lora.py \\
  --base_model Qwen/Qwen2-0.5B-Instruct \\
  --lora_path out/lora/hf_lora_hf_final.pth \\
  --lora_rank 8 \\
  --rope_2d_ratio 0.5 \\
  --mode chat

# å•æ¬¡ç”Ÿæˆ
python scripts/inference_hf_lora.py \\
  --base_model Qwen/Qwen2-0.5B-Instruct \\
  --lora_path out/lora/hf_lora_hf_final.pth \\
  --lora_rank 8 \\
  --mode generate \\
  --prompt "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
""".strip())

    print("\nâš ï¸  é‡è¦æç¤ºï¼š")
    print("-" * 80)
    print("""
1. âœ… pos2d å·²è‡ªåŠ¨å¤„ç†ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®
2. âœ… æ¨ç†è„šæœ¬è‡ªåŠ¨é‡å†™äº† prepare_inputs_for_generation
3. âœ… æ¯æ¬¡ç”Ÿæˆå‰ä¼šè‡ªåŠ¨è°ƒç”¨ set_rope_pos2d
4. âš ï¸  lora_rank å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´
5. âš ï¸  rope_2d_ratio å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´
6. âš ï¸  å¦‚æœè®­ç»ƒæ—¶ä½¿ç”¨äº† --patch_ropeï¼Œæ¨ç†æ—¶ä¹Ÿå¿…é¡»å¯ç”¨ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
""".strip())

    print("\nğŸ“š è¯¦ç»†æ–‡æ¡£ï¼š")
    print("-" * 80)
    print("- æ¨ç†æŒ‡å—: docs/INFERENCE_GUIDE.md")
    print("- è®­ç»ƒæ–‡æ¡£: docs/TRAIN_HF_LORA_USAGE.md")
    print("- ä¸»æ–‡æ¡£: README.md")
    print()


def main():
    parser = argparse.ArgumentParser(description="éªŒè¯ HuggingFace + LoRA + 2D RoPE æ¨ç†è®¾ç½®")
    parser.add_argument("--skip-imports", action="store_true", help="è·³è¿‡å¯¼å…¥æ£€æŸ¥")
    args = parser.parse_args()

    print("\n" + "=" * 80)
    print("HuggingFace + LoRA + 2D RoPE æ¨ç†æµç¨‹éªŒè¯")
    print("=" * 80 + "\n")

    checks = []

    if not args.skip_imports:
        checks.append(("æ¨¡å—å¯¼å…¥", check_imports()))
    checks.append(("è®­ç»ƒè„šæœ¬", check_training_script()))
    checks.append(("æ¨ç†è„šæœ¬", check_inference_script()))
    checks.append(("æ–‡æ¡£å®Œæ•´æ€§", check_documentation()))
    checks.append(("pos2d å·¥ä½œæµç¨‹", check_pos2d_workflow()))
    checks.append(("æ–‡ä»¶ç»“æ„", check_file_structure()))

    # æ‰“å°ç»“æœ
    print("=" * 80)
    print("éªŒè¯ç»“æœæ±‡æ€»")
    print("=" * 80)

    all_passed = True
    for name, result in checks:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{name:20s} {status}")
        if not result:
            all_passed = False

    print("=" * 80)

    if all_passed:
        print("\nâœ… æ‰€æœ‰éªŒè¯é€šè¿‡ï¼ç³»ç»Ÿå·²æ­£ç¡®é…ç½®")
        print_summary()
        return 0
    else:
        print("\nâŒ éƒ¨åˆ†éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯")
        return 1


if __name__ == "__main__":
    sys.exit(main())
